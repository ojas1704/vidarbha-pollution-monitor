import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from datetime import datetime, timedelta

# --- 1. CONFIGURATION & STYLING ---
st.set_page_config(page_title="Vidarbha Air Pulse V3.0", layout="wide", page_icon="üçÉ")

st.markdown("""
    <style>
    /* Force background to white and text to dark everywhere */
    .stApp { background-color: #ffffff; color: #1a1a1a; }
    h1, h2, h3, h4, h5, h6, p, span, div { color: #2E4053 !important; font-family: 'Segoe UI', sans-serif; }
    div[data-testid="stMetricValue"] { color: #1a1a1a !important; }
    .metric-container {
        background-color: #f0fdf4; border-left: 5px solid #28B463;
        padding: 20px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    div.stButton > button { background-color: #28B463; color: white !important; border-radius: 30px; border: none; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. DATA ENGINE (IMPROVED) ---
@st.cache_data
def get_base_data():
    # INCREASED: 5 Years of data (1825 days) for better learning
    dates = pd.date_range(end=datetime.today(), periods=1825)
    t = np.arange(1825)
    
    # Stronger Pattern for the Model to learn
    seasonal = 50 * np.sin(t / 180)  # Annual Cycle (Winter/Summer)
    weekly = 15 * np.sin(t / 7)      # Weekly Cycle
    trend = t * 0.02                 # Slight yearly increase (Urbanization)
    noise = np.random.normal(0, 5, 1825) # Reduced noise slightly
    
    aqi = 100 + seasonal + weekly + trend + noise
    aqi = np.clip(aqi, 40, 400)
    
    df = pd.DataFrame({'Date': dates, 'AQI': aqi})
    df.set_index('Date', inplace=True)
    return df

# --- 3. HYPER-TUNED LSTM MODEL ---
@st.cache_resource
def train_and_evaluate(df, traffic_stress=0, construction_stress=0):
    data = df.values
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)

    # Apply Stressors to recent data
    stress_factor = (traffic_stress * 0.005) + (construction_stress * 0.01)
    if stress_factor > 0:
        scaled_data[-90:] += stress_factor

    # Prediction window
    prediction_days = 60
    x, y = [], []
    for i in range(prediction_days, len(scaled_data)):
        x.append(scaled_data[i-prediction_days:i, 0])
        y.append(scaled_data[i, 0])
        
    x, y = np.array(x), np.array(y)
    x = np.reshape(x, (x.shape[0], x.shape[1], 1))

    # Split Data (80% Train, 20% Test)
    split_index = int(len(x) * 0.8)
    x_train, x_test = x[:split_index], x[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    # BUILD MODEL (TUNED)
    model = Sequential()
    # Increased Neurons to 64
    model.add(LSTM(units=64, return_sequences=True, input_shape=(x_train.shape[1], 1)))
    model.add(Dropout(0.2)) 
    model.add(LSTM(units=64))
    model.add(Dropout(0.2))
    model.add(Dense(units=1))
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    
    # TUNING: Increased Epochs to 50, Reduced Batch Size to 16
    # This makes training slower but MUCH more accurate
    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)
    model.fit(x_train, y_train, epochs=50, batch_size=16, verbose=0, callbacks=[early_stop])

    # Predictions
    predictions = model.predict(x_test, verbose=0)
    predictions = scaler.inverse_transform(predictions)
    y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

    # Error Metrics
    rmse = np.sqrt(mean_squared_error(y_test_actual, predictions))

    # Future Forecast (Next 7 Days)
    future_forecast = []
    current_batch = scaled_data[-prediction_days:].reshape(1, prediction_days, 1)
    for i in range(7):
        pred = model.predict(current_batch, verbose=0)[0,0]
        future_forecast.append(pred)
        new_step = np.array([[[pred]]])
        current_batch = np.append(current_batch[:,1:,:], new_step, axis=1)
    
    future_forecast = scaler.inverse_transform(np.array(future_forecast).reshape(-1, 1))
    
    return future_forecast, predictions, y_test_actual, rmse, df.index[split_index+prediction_days:]

# --- 4. UI LAYOUT ---

col1, col2 = st.columns([3, 1])
with col1:
    st.title("üå± Vidarbha Air Pulse V3.0")
    st.markdown("### Hyper-Tuned LSTM Model")
    st.write("Parameters: **50 Epochs**, **16 Batch Size**, **5 Years Data**. Optimized for generalization.")
with col2:
    st.image("https://images.unsplash.com/photo-1497435334941-8c899ee9e8e9?q=80&w=1974&auto=format&fit=crop", use_container_width=True)

st.markdown("---")

st.sidebar.header("‚öôÔ∏è Stress Test")
traffic = st.sidebar.slider("üö¶ Traffic Density (%)", 0, 100, 20)
construction = st.sidebar.slider("üèóÔ∏è Active Construction Sites", 0, 50, 5)

# Run Logic
df = get_base_data()
with st.spinner("Training Deep Learning Model... (This may take 30 seconds)"):
    forecast, test_preds, test_actual, rmse, test_dates = train_and_evaluate(df, traffic, construction)

tomorrows_aqi = int(forecast[0][0])

# Metrics
m1, m2, m3 = st.columns(3)
with m1:
    st.markdown(f'<div class="metric-container"><h3>Current AQI</h3><h1>{int(df["AQI"].iloc[-1])}</h1><p>Real-time Data</p></div>', unsafe_allow_html=True)
with m2:
    color = "#E74C3C" if tomorrows_aqi > 150 else "#28B463"
    st.markdown(f'<div class="metric-container" style="border-left: 5px solid {color};"><h3>Tomorrow Forecast</h3><h1 style="color:{color}">{tomorrows_aqi}</h1><p>Prediction</p></div>', unsafe_allow_html=True)
with m3:
    st.markdown(f'<div class="metric-container"><h3>Accuracy (RMSE)</h3><h1>¬±{int(rmse)}</h1><p>Validation Score</p></div>', unsafe_allow_html=True)

st.markdown("---")

tab1, tab2, tab3 = st.tabs(["üìä Forecast", "üìâ Validation (Truth vs AI)", "üó∫Ô∏è Map"])

with tab1:
    st.subheader("7-Day Forecast")
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df.index[-100:], y=df['AQI'].iloc[-100:], mode='lines', name='History', line=dict(color='#2E86C1')))
    future_dates = pd.date_range(start=df.index[-1] + timedelta(days=1), periods=7)
    fig.add_trace(go.Scatter(x=future_dates, y=forecast.flatten(), mode='lines+markers', name='AI Prediction', line=dict(color='#E74C3C', width=3)))
    fig.update_layout(template="plotly_white", height=450)
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.subheader("Did the model learn correctly?")
    st.write("Orange Line (AI) should closely follow the Grey Line (Reality).")
    fig_val = go.Figure()
    fig_val.add_trace(go.Scatter(x=test_dates, y=test_actual.flatten(), mode='lines', name='Actual', line=dict(color='lightgrey', width=2)))
    fig_val.add_trace(go.Scatter(x=test_dates, y=test_preds.flatten(), mode='lines', name='Predicted', line=dict(color='orange', width=2)))
    st.plotly_chart(fig_val, use_container_width=True)

with tab3:
    st.subheader("Regional Map")
    map_data = pd.DataFrame({
        'City': ['Nagpur', 'Amravati', 'Chandrapur', 'Akola', 'Wardha'],
        'lat': [21.1458, 20.9320, 19.9615, 20.7002, 20.7453],
        'lon': [79.0882, 77.7523, 79.2961, 77.0082, 78.6022],
        'AQI': [tomorrows_aqi, tomorrows_aqi-10, tomorrows_aqi+30, tomorrows_aqi-5, tomorrows_aqi-10]
    })
    fig_map = px.scatter_mapbox(map_data, lat="lat", lon="lon", color="AQI", size="AQI", zoom=6, mapbox_style="carto-positron")
    st.plotly_chart(fig_map, use_container_width=True)
